{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_test', 'X_train', 'X_val', 'y_test', 'y_train', 'y_val']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('SVHN_single_grey1.h5','r')\n",
    "data = f.get('SVHN_single_grey1.h5')\n",
    "data_as_array = np.array(data)\n",
    "list(f.keys())\n",
    "\n",
    "\n",
    "\n",
    "#data = pd.read_hdf('SVHN_single_grey1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<f4')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array(f['X_test'])\n",
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = f['X_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(f['y_test'])\n",
    "y_train = f['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 32, 32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 7, 2, ..., 7, 9, 2], dtype=uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = np.array(f['X_val'])\n",
    "y_val = np.array(f['y_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "valY = tf.keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n",
      "First 5 examples now are:  [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "\n",
    "# Normalize the data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', name='Layer_1'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Dropout layer\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model.add(tf.keras.layers.Dense(60, activation='relu', name='Layer_3'))\n",
    "model.add(tf.keras.layers.Dense(30, activation='relu', name='Layer_4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 237,396\n",
      "Trainable params: 235,348\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 19s 459us/sample - loss: 1.9655 - accuracy: 0.3109 - val_loss: 1.4115 - val_accuracy: 0.5378\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 17s 405us/sample - loss: 1.2348 - accuracy: 0.6017 - val_loss: 1.0062 - val_accuracy: 0.6890\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 17s 408us/sample - loss: 0.9996 - accuracy: 0.6884 - val_loss: 0.8600 - val_accuracy: 0.7334\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 17s 399us/sample - loss: 0.8801 - accuracy: 0.7235 - val_loss: 0.7727 - val_accuracy: 0.7624\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 17s 402us/sample - loss: 0.8021 - accuracy: 0.7500 - val_loss: 0.7151 - val_accuracy: 0.7812\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 17s 401us/sample - loss: 0.7449 - accuracy: 0.7680 - val_loss: 0.6431 - val_accuracy: 0.8042\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 17s 394us/sample - loss: 0.6992 - accuracy: 0.7813 - val_loss: 0.6071 - val_accuracy: 0.8161\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 16s 378us/sample - loss: 0.6588 - accuracy: 0.7937 - val_loss: 0.5704 - val_accuracy: 0.8290\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 16s 388us/sample - loss: 0.6270 - accuracy: 0.8022 - val_loss: 0.5665 - val_accuracy: 0.8300\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 16s 372us/sample - loss: 0.6000 - accuracy: 0.8118 - val_loss: 0.5240 - val_accuracy: 0.8416\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 16s 370us/sample - loss: 0.5721 - accuracy: 0.8209 - val_loss: 0.5378 - val_accuracy: 0.8385\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 16s 370us/sample - loss: 0.5569 - accuracy: 0.8257 - val_loss: 0.5094 - val_accuracy: 0.8456\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 16s 370us/sample - loss: 0.5319 - accuracy: 0.8328 - val_loss: 0.5570 - val_accuracy: 0.8318\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 16s 382us/sample - loss: 0.5122 - accuracy: 0.8383 - val_loss: 0.4817 - val_accuracy: 0.8551\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 16s 375us/sample - loss: 0.4954 - accuracy: 0.8425 - val_loss: 0.4831 - val_accuracy: 0.8550\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 16s 381us/sample - loss: 0.4821 - accuracy: 0.8473 - val_loss: 0.4510 - val_accuracy: 0.8647\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 16s 383us/sample - loss: 0.4633 - accuracy: 0.8522 - val_loss: 0.4548 - val_accuracy: 0.8629\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 16s 372us/sample - loss: 0.4509 - accuracy: 0.8567 - val_loss: 0.4741 - val_accuracy: 0.8571\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 15s 363us/sample - loss: 0.4318 - accuracy: 0.8615 - val_loss: 0.4225 - val_accuracy: 0.8746\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 15s 367us/sample - loss: 0.4232 - accuracy: 0.8661 - val_loss: 0.4365 - val_accuracy: 0.8711\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 15s 368us/sample - loss: 0.4079 - accuracy: 0.8706 - val_loss: 0.4544 - val_accuracy: 0.8652\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 16s 374us/sample - loss: 0.3991 - accuracy: 0.8723 - val_loss: 0.4116 - val_accuracy: 0.8782\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 15s 364us/sample - loss: 0.3892 - accuracy: 0.8760 - val_loss: 0.4031 - val_accuracy: 0.8817\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 15s 364us/sample - loss: 0.3763 - accuracy: 0.8800 - val_loss: 0.4146 - val_accuracy: 0.8787\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 16s 384us/sample - loss: 0.3658 - accuracy: 0.8840 - val_loss: 0.4260 - val_accuracy: 0.8735\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 18s 430us/sample - loss: 0.3615 - accuracy: 0.8852 - val_loss: 0.4098 - val_accuracy: 0.8828\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 16s 387us/sample - loss: 0.3493 - accuracy: 0.8880 - val_loss: 0.4035 - val_accuracy: 0.8833\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 15s 364us/sample - loss: 0.3441 - accuracy: 0.8913 - val_loss: 0.3961 - val_accuracy: 0.8859\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 15s 363us/sample - loss: 0.3316 - accuracy: 0.8952 - val_loss: 0.4138 - val_accuracy: 0.8794\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 16s 379us/sample - loss: 0.3250 - accuracy: 0.8967 - val_loss: 0.3922 - val_accuracy: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce80556d30>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, trainY, validation_data=(x_val, valY), epochs=30,\n",
    "          batch_size = 32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 2s - loss: 0.5347 - accuracy: 0.8390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6484762728214264, 0.839]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch = tf.keras.models.Sequential()\n",
    "\n",
    "# Reshape data from 2D to 1D -> 28x28 to 784\n",
    "model_batch.add(tf.keras.layers.Reshape((1024,),input_shape=(32,32,)))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch.add(tf.keras.layers.Dense(1000, activation='relu', name='Layer_1'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Dense(500, activation='relu', name='Layer_2'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Dropout layer\n",
    "#model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Hidden layers\n",
    "model_batch.add(tf.keras.layers.Dense(250, activation='relu', name='Layer_3'))\n",
    "\n",
    "# Normalize the data\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Dense(125, activation='relu', name='Layer_4'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output layer\n",
    "model_batch.add(tf.keras.layers.Dense(10, activation='softmax', name='Output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_2 (Reshape)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "Layer_1 (Dense)              (None, 1000)              1025000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1000)              4000      \n",
      "_________________________________________________________________\n",
      "Layer_2 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "Layer_3 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "Layer_4 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 10)                1260      \n",
      "=================================================================\n",
      "Total params: 1,694,481\n",
      "Trainable params: 1,688,933\n",
      "Non-trainable params: 5,548\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_batch.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 1.4295 - accuracy: 0.5249 - val_loss: 0.9501 - val_accuracy: 0.6991\n",
      "Epoch 2/30\n",
      "42000/42000 [==============================] - 65s 2ms/sample - loss: 0.9495 - accuracy: 0.6955 - val_loss: 0.7593 - val_accuracy: 0.7649\n",
      "Epoch 3/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.7778 - accuracy: 0.7535 - val_loss: 0.6877 - val_accuracy: 0.7826\n",
      "Epoch 4/30\n",
      "42000/42000 [==============================] - 62s 1ms/sample - loss: 0.6688 - accuracy: 0.7858 - val_loss: 0.6189 - val_accuracy: 0.8046\n",
      "Epoch 5/30\n",
      "42000/42000 [==============================] - 61s 1ms/sample - loss: 0.5800 - accuracy: 0.8146 - val_loss: 0.5242 - val_accuracy: 0.8383\n",
      "Epoch 6/30\n",
      "42000/42000 [==============================] - 2116s 50ms/sample - loss: 0.5073 - accuracy: 0.8405 - val_loss: 0.4949 - val_accuracy: 0.8463\n",
      "Epoch 7/30\n",
      "42000/42000 [==============================] - 43s 1ms/sample - loss: 0.4427 - accuracy: 0.8595 - val_loss: 0.4920 - val_accuracy: 0.8471\n",
      "Epoch 8/30\n",
      "42000/42000 [==============================] - 54s 1ms/sample - loss: 0.3844 - accuracy: 0.8802 - val_loss: 0.4510 - val_accuracy: 0.8606\n",
      "Epoch 9/30\n",
      "42000/42000 [==============================] - 81s 2ms/sample - loss: 0.3344 - accuracy: 0.8963 - val_loss: 0.4520 - val_accuracy: 0.8608\n",
      "Epoch 10/30\n",
      "42000/42000 [==============================] - 67s 2ms/sample - loss: 0.2911 - accuracy: 0.9097 - val_loss: 0.4400 - val_accuracy: 0.8657\n",
      "Epoch 11/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.2490 - accuracy: 0.9245 - val_loss: 0.4139 - val_accuracy: 0.8746\n",
      "Epoch 12/30\n",
      "42000/42000 [==============================] - 65s 2ms/sample - loss: 0.2181 - accuracy: 0.9341 - val_loss: 0.4198 - val_accuracy: 0.8739\n",
      "Epoch 13/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.1828 - accuracy: 0.9467 - val_loss: 0.4689 - val_accuracy: 0.8625\n",
      "Epoch 14/30\n",
      "42000/42000 [==============================] - 64s 2ms/sample - loss: 0.1556 - accuracy: 0.9546 - val_loss: 0.4136 - val_accuracy: 0.8804\n",
      "Epoch 15/30\n",
      "42000/42000 [==============================] - 61s 1ms/sample - loss: 0.1374 - accuracy: 0.9609 - val_loss: 0.3919 - val_accuracy: 0.8874\n",
      "Epoch 16/30\n",
      "42000/42000 [==============================] - 61s 1ms/sample - loss: 0.1159 - accuracy: 0.9676 - val_loss: 0.3898 - val_accuracy: 0.8897\n",
      "Epoch 17/30\n",
      "42000/42000 [==============================] - 62s 1ms/sample - loss: 0.0994 - accuracy: 0.9726 - val_loss: 0.4383 - val_accuracy: 0.8801\n",
      "Epoch 18/30\n",
      "42000/42000 [==============================] - 62s 1ms/sample - loss: 0.0828 - accuracy: 0.9782 - val_loss: 0.3773 - val_accuracy: 0.8981\n",
      "Epoch 19/30\n",
      "42000/42000 [==============================] - 63s 1ms/sample - loss: 0.0627 - accuracy: 0.9840 - val_loss: 0.3821 - val_accuracy: 0.8968\n",
      "Epoch 20/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.0528 - accuracy: 0.9874 - val_loss: 0.3783 - val_accuracy: 0.9008\n",
      "Epoch 21/30\n",
      "42000/42000 [==============================] - 69s 2ms/sample - loss: 0.0400 - accuracy: 0.9913 - val_loss: 0.3938 - val_accuracy: 0.8978\n",
      "Epoch 22/30\n",
      "42000/42000 [==============================] - 71s 2ms/sample - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.3947 - val_accuracy: 0.8996\n",
      "Epoch 23/30\n",
      "42000/42000 [==============================] - 72s 2ms/sample - loss: 0.0218 - accuracy: 0.9962 - val_loss: 0.3756 - val_accuracy: 0.9054\n",
      "Epoch 24/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.3744 - val_accuracy: 0.9075\n",
      "Epoch 25/30\n",
      "42000/42000 [==============================] - 67s 2ms/sample - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.3762 - val_accuracy: 0.9071\n",
      "Epoch 26/30\n",
      "42000/42000 [==============================] - 74s 2ms/sample - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.3796 - val_accuracy: 0.9097\n",
      "Epoch 27/30\n",
      "42000/42000 [==============================] - 66s 2ms/sample - loss: 0.0049 - accuracy: 0.9998 - val_loss: 0.3465 - val_accuracy: 0.9183\n",
      "Epoch 28/30\n",
      "42000/42000 [==============================] - 65s 2ms/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9203\n",
      "Epoch 29/30\n",
      "42000/42000 [==============================] - 62s 1ms/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9209\n",
      "Epoch 30/30\n",
      "42000/42000 [==============================] - 41s 977us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cee1288d68>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.fit(x_train, trainY, validation_data=(x_val, valY), epochs=30,\n",
    "          batch_size = 32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 4s - loss: 0.5276 - accuracy: 0.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8612443946003914, 0.835]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_batch.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "#Initialize model, reshape & normalize data\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape data from 2D (28,28) to 3D (28, 28, 1)\n",
    "model.add(tf.keras.layers.Reshape((32,32,1),input_shape=(32,32,)))\n",
    "\n",
    "#normalize data\n",
    "model.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add first convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(32, #Number of filters \n",
    "                                 kernel_size=(3,3), #Size of the filter\n",
    "                                 activation='relu'))\n",
    "\n",
    "#Add second convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "\n",
    "#Add MaxPooling layer\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten the output\n",
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dense layer\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "#Add another dropout layer\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "#Output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,625,870\n",
      "Trainable params: 1,625,868\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'h5py._hl.dataset.Dataset'>, <class 'NoneType'>\n",
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 178s 4ms/sample - loss: 1.8780 - accuracy: 0.3417 - val_loss: 1.1959 - val_accuracy: 0.6213\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 181s 4ms/sample - loss: 0.9539 - accuracy: 0.7018 - val_loss: 0.6102 - val_accuracy: 0.8244\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 200s 5ms/sample - loss: 0.6344 - accuracy: 0.8115 - val_loss: 0.4591 - val_accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 201s 5ms/sample - loss: 0.5093 - accuracy: 0.8487 - val_loss: 0.3927 - val_accuracy: 0.8915\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 186s 4ms/sample - loss: 0.4404 - accuracy: 0.8689 - val_loss: 0.3462 - val_accuracy: 0.9029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ce84665da0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,trainY,          \n",
    "          validation_data=(x_val,valY),\n",
    "          epochs=5,\n",
    "          batch_size=32, shuffle='batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/1 - 14s - loss: 0.4082 - accuracy: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43623367661237716, 0.88211113]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, testY, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
